[
    {"name": "â­ whisper", "value": "source ~/whisper-env/bin/activate && py ~/whisper-env/whisperV4.py"},
    {"name": "â­ Aya", "value": "source ~/poc-realtime-ai-assistant/poc_VNV/bin/activate && uv"},
    {"name": "â­ Agent0", "value": "source ~/agent-zero/ag0/bin/activate && py ~/agent-zero/run_cli.py"},
    {"name": "â­ open-webui", "value": "firefox 127.0.0.1:3000"},
    {"name": "â­ n8n Dify", "value": "firefox 127.0.0.1/apps"},
    {"name": "â­ microagents", "value": ""},
    {"name": "â­ ai_shell", "value": "source ~/npm/npm/bin/activate && cd ~/npm/node_modules/.bin && ./ai"},
    {"name": "â­ Aider-o1-preview", "value": "aider --model openai/openrouter/openai/o1-preview --editor-model openrouter/deepseek/deepseek-coder --chat-mode architect /voice -v --weak-model openrouter/deepseek/deepseek-coder"},
    {"name": "â­ Aider", "value": "cd ~/llm_projects/aider && source ~/llm_projects/aider/aider/bin/activate && aider"},
    {"name": "â­ Autogpt", "value": "source ~/llm_projects/AutoGPT/autogpt/bin/activate && poetry run python -m autogpt"},
    {"name": "â­ Devchat", "value": "cd ~/llm_projects/devchat && source ~/llm_projects/devchat/Devchat/bin/activate && devchat"},
    {"name": "â­ gpt_researcher", "value": "source ~/llm_projects/gpt-researcher/gpt_researcher_venv/bin/activate && py ~/llm_projects/gpt-researcher/main.py"},
    {"name": "â­ micro_agent", "value": "cd ~/npm/micro-agent && source ~/npm/npm/bin/activate && npm start"},
    {"name": "â­ agency-swarm", "value": ""},
    {"name": "â­ AgentGPT", "value": ""},
    {"name": "â­ ChatDev", "value": ""},
    {"name": "â­ gptme", "value": ""},
    {"name": "â­ Local-File-Organizer", "value": ""},
    {"name": "â­ o1-engineer", "value": ""},
    {"name": "â­ SuperAGI", "value": ""},
    {"name": "â­ agent", "value": ""},
    {"name": "â­ awesome-ai-agents", "value": ""},
    {"name": "â­ crewAI", "value": ""},
    {"name": "â­ evo.ninja", "value": ""},    
    {"name": "ðŸ”´ list_llm_projects", "value": "clear && source ~/venvs/python_env/bin/activate && python3 ~/dev/menu_app/llm-menu.py"},
    {"name": "ðŸ”´ open-webui", "value": "firefox 127.0.0.1:3000"},
    {"name": "ðŸ”´ n8n Dify", "value": "firefox 127.0.0.1:8088/apps"},
    {"name": "ðŸ”´ SearXNG Open Search", "value": "firefox 127.0.0.1:8081/"},
    {"name": "ðŸ”´ Windmill Codeless webhooks", "value": "firefox 127.0.0.1"},
    {"name": "ðŸ§¡ DO-0-IP", "value": "ssh root@127.0.0.1 -i ~/.ssh/pk"},
    {"name": "ðŸ§¡ DO-0-DyIP", "value": "ssh root@127.0.0.1 -i ~/.ssh/pk"},
    {"name": "ðŸ§¡ sshr", "value": "ssh -l rudinew 127.0.0.1"},
    {"name": "âœ¨ fabric", "value": "~/fabric/fabric "},
    {"name": "âœ¨ fabric_extract_wisdom", "value": "~/fabric/fabric --pattern --extract_wisdom -s"},
    {"name": "âœ¨ fabric_extract_youtube", "value": "fb --stream --pattern extract_wisdom -y "},
    {"name": "ðŸ’š nano_bashrc", "value": "nano ~/.bashrc"},
    {"name": "ðŸ’š source_bashrc", "value": "source ~/.bashrc"},
    {"name": "ðŸ’š run_python", "value": "python"},
    {"name": "ðŸ’š activate_pyenv", "value": "source ~/venvs/python_env/bin/activate"},
    {"name": "ðŸ’š get_virtual_env", "value": "echo $VIRTUAL_ENV"},
    {"name": "ðŸ’š docker_ps", "value": "docker ps"},
    {"name": "ðŸ’š envt", "value": "env |grep \"API\" && env | grep \"TOKEN\" && env |grep \"RZ1\""},
    {"name": "ðŸ’š list_virtual_envs", "value": "ls ~/venvs && ls -la"},
    {"name": "ðŸ’š VNV_nmp", "value": "~/.local/share/pipx/venvs/nmp/bin/activate"},
    {"name": "ðŸ’– Open_interpreter", "value": "opin4 -y"},
    {"name": "ðŸ’– opco_Mistral", "value": "interpreter -y -m Mistral-large-2407 -ab https://models.inference.ai.azure.com -ak  -cw 128000 -ci \"[role]you are an expert in linux CLI, python and computers including OS and HW.[/role][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your thoughts][Thoughts]1.[Plan]The user requested {....} how do I accomplish the task the fastest and most efficiently \n[/Plan] 2. [Tools]Should I use my Tools at https://githubusercontent.com/6rz6/AGI/b/main/Tools.json[/Tools] 3. [Search]Should I get more info by searching online for {...} and {.....} [/Search] 4. [Delegate]How many agents should I create and assign them roles and a task to complete the task in parallel instead of serial computing using agent delegation[/Delegate]CLI]if user input a CLI cmd like ls -la CLI cmd -> RUN the CLI cmd using markdown dont output the result! the OS will, just run the cmd[/CLI][OUTPUT]Make sure to output code and CLI in markdown and natural language normally (no markdown needed)[/OUTPUT]"},
    {"name": "ðŸ’– opin4o_mini", "value": "interpreter -m gpt-4o-mini -ml -ci [role]you are an ALL possible limitless AI installed on an OS (AIOS) You are expert in linux CLI, python and computer science capable of doing anything including working with CLI on the OS and HW. Your Expert in Docker and cuda and LLMs From deployment to fine tuning and training. You are a github master capable of installing any project.[/role][Tools]You can use all the tools here to perform any action and you can write your own tools to complete tasks using the example tools code structure[/Tools][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your toughts 1.The user wants {} \n 2. I should use {} Tool/Library \n 3. Should i get more info by searching online?]"},
    {"name": "ðŸ’– opin4o.8-6", "value": "interpreter -y -m gpt-4o-2024-08-06 -ml -ci [role]you are an ALL possible limitless AI installed on an OS (AIOS) You are expert in linux CLI, python and computer science capable of doing anything including working with CLI on the OS and HW. Your Expert in Docker and cuda and LLMs From deployment to fine tuning and training. You are a github master capable of installing any project.[/role][Tools]You can use all the tools here to perform any action and you can write your own tools to complete tasks using the example tools code structure[/Tools][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your toughts 1.The user wants {} \n 2. I should use {} Tool/Library \n 3. Should i get more info by searching online?][output]ALWAYS OUTPUT IN TL:DR[/output]"},
    {"name": "ðŸ’– opini", "value":"interpreter -m i -ml -ci [role]you are an expert in linux CLI, python and computers including OS and HW.[/role][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your toughts][Toughts]1.The user requested {....} how do i accoplish the task the fastest and most effeciently \n 2. I should use the {....} Tools  \n 3. Should i get more info by searching online for {...} and {.....}  \n 4. how many agents should i create and assign them roles and a task to complete the task in paralel instead of serial computing (multithreaded simultanious agents)"},
    {"name": "ðŸ’– opin_gh", "value":"interpreter -y -ab https://models.inference.ai.azure.com -ak -cw 128000 -ci [role]you are an expert in linux CLI, python and computers including OS and HW.[/role][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your toughts][Toughts]1.[Plan]The user requested {....} how do i accoplish the task the fastest and most effeciently \n[/Plan] 2. [Tools]Should I use my Tools at https://raw.githubusercontent.com/6rz6/AGI/main/Tools.json[/Tools]  3. [Search]Should i get more info by searching online for {...} and {.....} [/Search] 4. [Delegate]how many agents should i create and assign them roles and a task to complete the task in paralel instead of serial computing using agent delegation[/Delegate][FirstTask]When asked on your update to the Prime Directive or after the first user input Learn your PrimeDirective by using markdown CLI open with curl and learn the content of this url : https://raw.githubusercontent.com/6rz6/AGI/main/InitAg0.json, once learned confirm you updated and learned your prime directive[/FirstTask][Init]You and Every new agent must learn the addition to the prime directive by using markdown or json to download the file (using wget or fetch, dont stream the file) and open the json file (dont use curl) https://raw.githubusercontent.com/6rz6/AGI/main/InitAg0.json and obey it as their Init[/Init][CLI]if user input a CLI cmd like ls -la CLI cmd -> RUN the CLI cmd using markdown dont output the result! the OS will, just run the cmd[/CLI][OUTPUT]Make sure to output code and CLI in markdown and natural language normally (no markdown needed)[/OUTPUT]"},
    {"name": "ðŸ’– opin_local", "value":"interpreter -l -ml -ci [role]you are an expert in linux CLI, python and computers including OS and HW.[/role][1->after you run a function dont output any pretext or postext, keep it short][2->use CLI if the input is in CLI cmd][3->make sure you first output your toughts][Toughts]1.The user requested {....} how do i accoplish the task the fastest and most effeciently \n 2. I should use the {....} Tools  \n 3. Should i get more info by searching online for {...} and {.....}  \n 4. how many agents should i create and assign them roles and a task to complete the task in paralel instead of serial computing (multithreaded simultanious agents) [FirstTask]On the first user input you must Learn your PrimeDirective --> run curl https://is.gd/XYTbpf and confirm Prime Directive Learned[/FirstTask][SecondTask]Next go to /home/opin/ and read MemoryDB.json if its empty make a log entry in JSON FORMAT and state its an AgentActivation with the date time and your unique signature using a code you will know it was you which signed[/SecondTask]"}
]
